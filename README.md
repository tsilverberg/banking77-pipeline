# ğŸ¦ Banking77 Intent Classification Pipeline

This project demonstrates a **mini MLOps pipeline** for banking-related intent classification using the [Banking77 dataset](https://github.com/PolyAI-LDN/task-specific-datasets). It covers:

- âœ… Data ingestion & transformation  
- âœ… Feature engineering (TF-IDF)  
- âœ… Model training (Logistic Regression)  
- âœ… Model persistence (joblib)  
- âœ… Mock deployment (FastAPI API)

# ğŸ’¡ Why This Project?

I'm currently working on **agentic LLM solutions**, where intent classification is a critical component of agent routing and coordination. However, these solutions often rely on heavyweight or expensive architectures like OpenAI, which can:

- Introduce latency  
- Require fine-tuning or vector databases  
- Be cost-prohibitive at scale

With this project, I wanted to:

- âœ… Revisit **traditional ML** techniques like TF-IDF and Logistic Regression  
- âœ… Benchmark how **â€œold-schoolâ€ ML** stacks up for narrow-domain intent detection  
- âœ… Build a pipeline thatâ€™s fast, explainable, and cost-effective  

Itâ€™s a practical exploration of the tradeoffs between **simple pipelines** and **modern LLM architectures** â€” and a reminder that **not all AI problems need transformers.**


---

## ğŸ“ Project Structure

```
banking77_pipeline/
â”œâ”€â”€ .env
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py               â† FastAPI app for inference
â”‚   â”œâ”€â”€ run_etl.py           â† Extracts and converts CSV â†’ JSONL
â”‚   â”œâ”€â”€ run_training.py      â† Trains model and saves artifacts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ config.py        â† Centralized path + env handling
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ data.py
â”‚       â””â”€â”€ model.py
â””â”€â”€ README.md
```

---

## ğŸ“¦ Setup

### 1. Clone and install dependencies

```bash
git clone https://github.com/tsilverberg/banking77-pipeline.git
cd banking77_pipeline
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure `.env`

```dotenv
# .env file at project root
DATA_SOURCE_REPO_URL=https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/
TRAIN_JSON=banking77_train.jsonl
TEST_JSON=banking77_test.jsonl
MODEL_FILE=models/intent_classifier.pkl
VECTORIZER_FILE=models/vectorizer.pkl
```

---

## ğŸ”„ Run the Pipeline

### âœ… Extract & Save JSONL

```bash
python3 src/run_etl.py
```

### âœ… Train the model

```bash
python3 src/run_training.py
```

---

## ğŸš€ Run the API

### Start server

```bash
cd src/
uvicorn app:app --reload
```

### Open in browser

[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

### Example request

```json
POST /predict
{
  "text": "How can I reset my PIN?"
}
```

### Example response

```json
{
  "text": "How can I reset my PIN?",
  "predicted_intent": "pin_change"
}
```

---

## ğŸ§ª Next Steps

- Add `confidence_score` via `model.predict_proba`
- Write unit tests for `data.py` and `model.py`
- Add Dockerfile for deployability
- CI integration or model versioning

---

## ğŸ“š Credits

- [PolyAI Banking77 Dataset](https://github.com/PolyAI-LDN/task-specific-datasets)
- [FastAPI](https://fastapi.tiangolo.com/)
- [scikit-learn](https://scikit-learn.org/)
