# ğŸ¦ Banking77 Intent Classification Pipeline

This project demonstrates a **mini MLOps pipeline** for banking-related intent classification using the [Banking77 dataset](https://github.com/PolyAI-LDN/task-specific-datasets). It covers:

- âœ… Data ingestion & transformation  
- âœ… Feature engineering (TF-IDF)  
- âœ… Model training (Logistic Regression)  
- âœ… Model persistence (joblib)  
- âœ… Mock deployment (FastAPI API)

---

## ğŸ“ Project Structure

```
banking77_pipeline/
â”œâ”€â”€ .env
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py               â† FastAPI app for inference
â”‚   â”œâ”€â”€ run_etl.py           â† Extracts and converts CSV â†’ JSONL
â”‚   â”œâ”€â”€ run_training.py      â† Trains model and saves artifacts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ config.py        â† Centralized path + env handling
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ data.py
â”‚       â””â”€â”€ model.py
â””â”€â”€ README.md
```

---

## ğŸ“¦ Setup

### 1. Clone and install dependencies

```bash
git clone <your-repo-url>
cd banking77_pipeline
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure `.env`

```dotenv
# .env file at project root
DATA_SOURCE_REPO_URL=https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/
TRAIN_JSON=banking77_train.jsonl
TEST_JSON=banking77_test.jsonl
MODEL_FILE=models/intent_classifier.pkl
VECTORIZER_FILE=models/vectorizer.pkl
```

---

## ğŸ”„ Run the Pipeline

### âœ… Extract & Save JSONL

```bash
python3 src/run_etl.py
```

### âœ… Train the model

```bash
python3 src/run_training.py
```

---

## ğŸš€ Run the API

### Start server

```bash
cd src/
uvicorn app:app --reload
```

### Open in browser

[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

### Example request

```json
POST /predict
{
  "text": "How can I reset my PIN?"
}
```

### Example response

```json
{
  "text": "How can I reset my PIN?",
  "predicted_intent": "pin_change"
}
```

---

## ğŸ§ª Next Steps

- Add `confidence_score` via `model.predict_proba`
- Write unit tests for `data.py` and `model.py`
- Add Dockerfile for deployability
- CI integration or model versioning

---

## ğŸ“š Credits

- [PolyAI Banking77 Dataset](https://github.com/PolyAI-LDN/task-specific-datasets)
- [FastAPI](https://fastapi.tiangolo.com/)
- [scikit-learn](https://scikit-learn.org/)
