"""
ðŸŽ¯ run_training.py

This script orchestrates the full training pipeline:
1. Load data from JSONL (path from .env)
2. Transform text into features using TF-IDF
3. Train a Logistic Regression classifier
4. Evaluate performance
5. Save model and vectorizer artifacts
"""

import os
from dotenv import load_dotenv
from training.data import load_banking77_from_json
from training.features import extract_features
from training.model import train_model, evaluate_model, save_model

# Load environment variables
load_dotenv()

def main():
    print("ðŸ“¦ Loading Banking77 dataset...")
    train_df, test_df = load_banking77_from_json()

    print("ðŸ”§ Extracting TF-IDF features...")
    X_train, X_test, vectorizer = extract_features(train_df["text"], test_df["text"])

    print("ðŸ¤– Training Logistic Regression model...")
    model = train_model(X_train, train_df["category"])

    print("ðŸ“Š Evaluating model performance...")
    evaluate_model(model, X_test, test_df["category"])

    print("ðŸ’¾ Saving model and vectorizer...")
    save_model(model, vectorizer)

    print("âœ… Training pipeline completed!")

if __name__ == "__main__":
    main()
